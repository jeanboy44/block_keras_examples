{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 사용할 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "    \n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "        \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "\n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0]*width), int(ipt[1]*height)] = 1\n",
    "        \n",
    "    return img.reshape(width, height, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터셋 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "x_train_1d = x_train.reshape(x_train.shape[0], width*height)\n",
    "x_val_1d = x_val.reshape(x_val.shape[0], width*height)\n",
    "x_test_1d = x_test.reshape(x_test.shape[0], width*height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim = width*height))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 학습과정 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 4667.1595 - val_loss: 396.5162\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 270.4136 - val_loss: 250.1918\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 0s 172us/step - loss: 206.6287 - val_loss: 221.9233\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 0s 172us/step - loss: 153.3510 - val_loss: 159.2873\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 0s 190us/step - loss: 102.9293 - val_loss: 132.1230\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 0s 185us/step - loss: 77.4726 - val_loss: 152.5480\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 60.1921 - val_loss: 116.6930\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 47.8563 - val_loss: 135.8758\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 0s 186us/step - loss: 34.8289 - val_loss: 119.8972\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 24.3763 - val_loss: 118.9473\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 19.5926 - val_loss: 104.2166\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 19.7408 - val_loss: 110.9012\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 12.7537 - val_loss: 109.7485\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 10.2021 - val_loss: 103.4822\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 6.2966 - val_loss: 106.8992\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 5.6551 - val_loss: 106.9932\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 4.0469 - val_loss: 108.0802\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 0s 172us/step - loss: 2.8822 - val_loss: 119.1611\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 0s 183us/step - loss: 3.5031 - val_loss: 107.1431\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 0s 188us/step - loss: 1.8571 - val_loss: 107.4074\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 0s 176us/step - loss: 1.4930 - val_loss: 105.2329\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 0s 178us/step - loss: 0.8285 - val_loss: 105.6531\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.4865 - val_loss: 106.9443\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 0s 188us/step - loss: 0.4247 - val_loss: 106.6103\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.3301 - val_loss: 105.7053\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.3896 - val_loss: 106.7827\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.3201 - val_loss: 107.5318\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.4815 - val_loss: 108.2832\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 0.6237 - val_loss: 107.3968\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 0.3968 - val_loss: 105.8929\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 0.2475 - val_loss: 107.3464\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2610 - val_loss: 105.8427\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.1770 - val_loss: 106.5267\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.1835 - val_loss: 105.8901\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.1358 - val_loss: 106.5254\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.2042 - val_loss: 105.1814\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 0s 184us/step - loss: 0.4276 - val_loss: 104.0240\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 0s 182us/step - loss: 0.8157 - val_loss: 107.7249\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 1.1137 - val_loss: 110.4355\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 2.5249 - val_loss: 108.0654\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 0s 177us/step - loss: 2.7954 - val_loss: 105.2704\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 5.4039 - val_loss: 113.9104\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 12.4717 - val_loss: 107.8838\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 0s 169us/step - loss: 7.5870 - val_loss: 116.6537\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 9.8491 - val_loss: 118.6299\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 11.4231 - val_loss: 115.7110\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 0s 168us/step - loss: 9.1471 - val_loss: 112.3354\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 11.9218 - val_loss: 102.8198\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 14.0775 - val_loss: 111.5376\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 7.0005 - val_loss: 127.3134\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 0s 178us/step - loss: 8.7104 - val_loss: 124.5067\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 0s 191us/step - loss: 4.3103 - val_loss: 108.9631\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 0s 184us/step - loss: 2.5119 - val_loss: 105.3834\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.5465 - val_loss: 109.5615\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 0s 177us/step - loss: 0.9575 - val_loss: 105.9908\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 0.9229 - val_loss: 108.0843\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 0.4269 - val_loss: 107.8784\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.2702 - val_loss: 107.4044\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 0s 168us/step - loss: 0.4259 - val_loss: 108.3525\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.2499 - val_loss: 106.1137\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.3688 - val_loss: 107.2347\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.5322 - val_loss: 107.3559\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.3464 - val_loss: 108.6124\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.2655 - val_loss: 109.8616\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.9457 - val_loss: 104.7185\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 3.8034 - val_loss: 109.8436\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 4.2129 - val_loss: 107.0462\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 3.2806 - val_loss: 111.4043\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 4.2199 - val_loss: 105.4809\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 7.8374 - val_loss: 111.1795\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 4.1239 - val_loss: 108.6107\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 2.6571 - val_loss: 106.3495\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 2.0954 - val_loss: 104.5440\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 2.0264 - val_loss: 108.4964\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 2.3981 - val_loss: 111.6765\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 2.5873 - val_loss: 110.9653\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 6.1368 - val_loss: 116.4978\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 9.5879 - val_loss: 111.0143\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 14.4658 - val_loss: 148.5048\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 46.9456 - val_loss: 122.9850\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 26.1809 - val_loss: 145.3088\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 29.1375 - val_loss: 112.2507\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 5.8866 - val_loss: 109.7948\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 8.0022 - val_loss: 109.3817\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 4.3276 - val_loss: 111.5360\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 0s 172us/step - loss: 2.1564 - val_loss: 106.7554\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 1.4460 - val_loss: 105.4061\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 1.0416 - val_loss: 109.0197\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.5000 - val_loss: 108.2566\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 1.2388 - val_loss: 107.1927\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.8929 - val_loss: 106.1357\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.4280 - val_loss: 108.4894\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.2034 - val_loss: 107.5144\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.1679 - val_loss: 107.7330\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.1100 - val_loss: 108.9951\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.0834 - val_loss: 107.1957\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.1030 - val_loss: 107.0927\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.0966 - val_loss: 108.0130\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.0486 - val_loss: 107.3146\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.0611 - val_loss: 108.9036\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.0387 - val_loss: 107.5352\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.0236 - val_loss: 107.9531\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.0175 - val_loss: 107.9527\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.0135 - val_loss: 107.4969\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.0115 - val_loss: 107.9426\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.0114 - val_loss: 107.3507\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.0155 - val_loss: 107.4859\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0309 - val_loss: 107.3094\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.0564 - val_loss: 106.5535\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.1931 - val_loss: 107.1047\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.4711 - val_loss: 107.3429\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.6929 - val_loss: 107.3541\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 22.9083 - val_loss: 136.7755\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 46.1244 - val_loss: 180.3820\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 45.7671 - val_loss: 122.1905\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 10.0262 - val_loss: 109.1966\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 4.4198 - val_loss: 128.8841\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 7.9463 - val_loss: 113.3178\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 2.5190 - val_loss: 109.9819\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 1.2317 - val_loss: 110.9973\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.7736 - val_loss: 110.2025\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.4979 - val_loss: 110.1057\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.5366 - val_loss: 110.3513\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.4635 - val_loss: 107.9412\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.1934 - val_loss: 107.9374\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.2542 - val_loss: 108.7077\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.1347 - val_loss: 108.5743\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.0846 - val_loss: 108.6623\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.0531 - val_loss: 109.1625\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.0634 - val_loss: 107.6196\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 0.0838 - val_loss: 107.1167\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.0707 - val_loss: 107.8584\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.0651 - val_loss: 107.8483\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.1200 - val_loss: 109.1458\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.2588 - val_loss: 111.0040\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 1.2663 - val_loss: 107.8251\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 1.4943 - val_loss: 107.6507\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.7499 - val_loss: 108.9303\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 0.4762 - val_loss: 111.2472\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 4.0146 - val_loss: 106.9296\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 2.4044 - val_loss: 109.1945\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 1.3116 - val_loss: 109.5751\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 1.0620 - val_loss: 109.0476\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.6954 - val_loss: 109.3481\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.6086 - val_loss: 109.6172\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.8604 - val_loss: 117.4582\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 0s 169us/step - loss: 1.7768 - val_loss: 112.2568\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 1.8871 - val_loss: 116.2667\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 4.8799 - val_loss: 109.9406\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 5.9114 - val_loss: 107.9560\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 8.9421 - val_loss: 146.1998\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 10.2089 - val_loss: 111.9627\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 17.9928 - val_loss: 175.8735\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 16.2406 - val_loss: 113.0672\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 9.8203 - val_loss: 114.3113\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 2.8557 - val_loss: 116.1696\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 1.5375 - val_loss: 111.9196\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 1.1673 - val_loss: 113.4345\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 1.2198 - val_loss: 108.0036\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.8226 - val_loss: 109.9763\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 0s 168us/step - loss: 0.4682 - val_loss: 114.4058\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.5169 - val_loss: 108.4387\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.7644 - val_loss: 109.9123\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 0.3777 - val_loss: 110.4479\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.5017 - val_loss: 110.0095\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.3170 - val_loss: 112.2916\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.6557 - val_loss: 110.2578\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.2819 - val_loss: 111.3833\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.2334 - val_loss: 110.3435\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.3100 - val_loss: 107.4773\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.5087 - val_loss: 111.3406\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3524 - val_loss: 111.3366\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.3494 - val_loss: 109.1699\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.3643 - val_loss: 109.8899\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2923 - val_loss: 111.7648\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.2267 - val_loss: 112.0429\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 0.2935 - val_loss: 110.0975\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 1.1371 - val_loss: 111.3462\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 1.4746 - val_loss: 122.9164\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 3.4346 - val_loss: 109.5375\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 0s 170us/step - loss: 1.8705 - val_loss: 110.6971\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 2.3026 - val_loss: 106.9167\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 3.9134 - val_loss: 111.3674\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 7.8640 - val_loss: 114.1486\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 0s 169us/step - loss: 9.8049 - val_loss: 108.2699\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 11.8153 - val_loss: 111.2720\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 6.5350 - val_loss: 128.7804\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 4.0390 - val_loss: 111.7240\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 6.6240 - val_loss: 110.1968\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 2.5272 - val_loss: 108.1832\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 1.9844 - val_loss: 111.0641\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 0s 170us/step - loss: 1.0851 - val_loss: 121.0156\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.9111 - val_loss: 114.0189\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 1.2367 - val_loss: 110.7298\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 1.4360 - val_loss: 118.3251\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 1.0899 - val_loss: 116.8778\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 1.0193 - val_loss: 114.4916\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.5070 - val_loss: 111.1485\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.5431 - val_loss: 109.0513\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 1.0055 - val_loss: 113.1926\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 1.1017 - val_loss: 111.1404\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.4761 - val_loss: 111.4270\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 0.3751 - val_loss: 112.9336\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.5899 - val_loss: 113.8428\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.6567 - val_loss: 110.1563\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 1.0639 - val_loss: 121.3450\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 1.9536 - val_loss: 112.1914\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 1.9232 - val_loss: 109.6894\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 4.9570 - val_loss: 114.1650\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 2.3527 - val_loss: 108.4115\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 2.6330 - val_loss: 121.4715\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 3.7035 - val_loss: 123.2984\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 2.3606 - val_loss: 108.5307\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 0s 169us/step - loss: 3.2612 - val_loss: 116.2466\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 3.0808 - val_loss: 111.5341\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 1.8560 - val_loss: 108.1672\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 1.9681 - val_loss: 113.1505\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 2.1174 - val_loss: 123.4785\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 5.3701 - val_loss: 109.9328\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 4.4333 - val_loss: 108.7527\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 2.1661 - val_loss: 109.2627\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 3.2428 - val_loss: 115.7356\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 2.2930 - val_loss: 111.9585\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 1.6302 - val_loss: 111.1768\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 1.3096 - val_loss: 111.4794\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.7823 - val_loss: 110.4939\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.5317 - val_loss: 111.3480\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.4306 - val_loss: 113.2799\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.4247 - val_loss: 113.8717\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4978 - val_loss: 109.8019\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.9743 - val_loss: 113.9581\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 1.2086 - val_loss: 112.8393\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 2.9958 - val_loss: 110.4295\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 4.8075 - val_loss: 108.9530\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 10.9581 - val_loss: 106.6016\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 18.6598 - val_loss: 117.3378\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 7.8984 - val_loss: 115.4988\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 3.6646 - val_loss: 112.8602\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 2.8128 - val_loss: 123.3933\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 1.4596 - val_loss: 113.7853\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.8634 - val_loss: 112.9131\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.5058 - val_loss: 112.5078\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.5127 - val_loss: 111.9192\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 0s 172us/step - loss: 0.2540 - val_loss: 112.2043\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.2017 - val_loss: 112.1845\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.2121 - val_loss: 111.6679\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.2855 - val_loss: 114.2559\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.1164 - val_loss: 112.6238\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1737 - val_loss: 114.0540\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.1236 - val_loss: 112.6814\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1649 - val_loss: 114.0308\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.2345 - val_loss: 116.7065\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 0.7552 - val_loss: 116.3094\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.7486 - val_loss: 115.7273\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.7438 - val_loss: 113.5966\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.9578 - val_loss: 111.3231\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 1.7683 - val_loss: 117.1283\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 2.1251 - val_loss: 117.7272\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 4.2687 - val_loss: 108.7650\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 3.6904 - val_loss: 112.7417\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 2.9227 - val_loss: 111.5271\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 2.5289 - val_loss: 117.9488\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 1.3131 - val_loss: 113.3360\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.7847 - val_loss: 114.0533\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.8125 - val_loss: 114.4464\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.5027 - val_loss: 116.0663\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 1.0499 - val_loss: 111.7584\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 1.5685 - val_loss: 111.4189\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.7078 - val_loss: 111.5705\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6211 - val_loss: 112.2428\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3887 - val_loss: 112.5939\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 1.2240 - val_loss: 128.7908\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 5.3730 - val_loss: 114.8252\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 4.6141 - val_loss: 132.3963\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 4.5712 - val_loss: 112.1909\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 2.7970 - val_loss: 114.9960\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 1.9446 - val_loss: 114.8956\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 1.4410 - val_loss: 112.0769\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.8306 - val_loss: 116.2203\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.7959 - val_loss: 113.5865\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6297 - val_loss: 111.7858\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.7518 - val_loss: 118.8072\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 1.3240 - val_loss: 115.3681\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.9433 - val_loss: 112.0567\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.8229 - val_loss: 110.6460\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 4.7535 - val_loss: 126.2408\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 0s 170us/step - loss: 8.5896 - val_loss: 119.8648\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 6.7064 - val_loss: 112.8706\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 11.5739 - val_loss: 111.5236\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 8.3670 - val_loss: 113.2702\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 2.4474 - val_loss: 118.0345\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 1.3515 - val_loss: 110.9486\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.6047 - val_loss: 113.4368\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.5559 - val_loss: 113.0496\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3895 - val_loss: 113.2913\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4100 - val_loss: 111.9263\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.2130 - val_loss: 111.3051\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1440 - val_loss: 112.1378\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.1370 - val_loss: 112.8748\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1006 - val_loss: 112.6518\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.0635 - val_loss: 113.9471\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.0516 - val_loss: 112.8463\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.0316 - val_loss: 112.6879\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.0221 - val_loss: 113.2531\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.0175 - val_loss: 113.3392\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.0192 - val_loss: 112.2605\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.0192 - val_loss: 113.1132\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0349 - val_loss: 113.0726\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.0451 - val_loss: 113.5445\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1446 - val_loss: 112.8480\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.1685 - val_loss: 115.0226\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 1.2553 - val_loss: 110.5543\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 3.1134 - val_loss: 115.5962\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 5.5435 - val_loss: 117.6340\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 9.3983 - val_loss: 141.3840\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 14.2579 - val_loss: 114.2164\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 7.3186 - val_loss: 114.9885\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 6.6241 - val_loss: 114.4403\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 11.9429 - val_loss: 110.1437\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 4.4625 - val_loss: 114.3012\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 2.0459 - val_loss: 118.4110\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 1.3043 - val_loss: 113.6347\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 1.0219 - val_loss: 118.2522\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.7162 - val_loss: 112.3969\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3092 - val_loss: 112.5391\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2478 - val_loss: 111.9368\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3541 - val_loss: 111.4429\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2495 - val_loss: 109.9971\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.1797 - val_loss: 112.0035\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.1730 - val_loss: 111.1695\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.2166 - val_loss: 112.5898\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1031 - val_loss: 112.6928\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.0695 - val_loss: 111.5949\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.0371 - val_loss: 112.9324\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.0507 - val_loss: 111.4263\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0315 - val_loss: 111.7368\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.0470 - val_loss: 111.9334\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0476 - val_loss: 111.5148\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0539 - val_loss: 112.7299\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.0369 - val_loss: 111.5323\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.0941 - val_loss: 114.3003\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.2476 - val_loss: 113.4153\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.2467 - val_loss: 111.6696\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 0s 183us/step - loss: 0.1063 - val_loss: 111.1966\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.0944 - val_loss: 111.5009\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 0s 177us/step - loss: 0.1501 - val_loss: 111.5836\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.3905 - val_loss: 111.7824\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.3468 - val_loss: 113.5367\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 0s 169us/step - loss: 0.2553 - val_loss: 110.1968\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 0s 169us/step - loss: 0.2804 - val_loss: 111.3975\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.2103 - val_loss: 110.1825\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.4272 - val_loss: 115.7400\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.8087 - val_loss: 115.4558\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 1.2461 - val_loss: 111.2455\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 3.5640 - val_loss: 112.5068\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 6.1844 - val_loss: 109.2940\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 8.9642 - val_loss: 114.3011\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 9.5083 - val_loss: 106.3557\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 11.2150 - val_loss: 122.2426\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 8.8549 - val_loss: 111.2362\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 4.4211 - val_loss: 109.9505\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 1.4585 - val_loss: 116.8754\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.9703 - val_loss: 114.0655\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.4281 - val_loss: 110.8865\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4753 - val_loss: 110.3677\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.5168 - val_loss: 112.6085\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.2319 - val_loss: 111.1074\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2093 - val_loss: 111.9426\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1307 - val_loss: 111.9687\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.1197 - val_loss: 112.7699\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0925 - val_loss: 113.3908\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0613 - val_loss: 112.2010\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0711 - val_loss: 111.9834\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.0603 - val_loss: 111.9084\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0399 - val_loss: 111.5301\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0560 - val_loss: 110.6154\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2069 - val_loss: 111.0926\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.1595 - val_loss: 111.5881\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0909 - val_loss: 111.8150\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0875 - val_loss: 112.2861\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0772 - val_loss: 111.2833\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0592 - val_loss: 111.7993\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0823 - val_loss: 112.0191\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1361 - val_loss: 111.5634\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1550 - val_loss: 111.0582\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.1658 - val_loss: 110.9776\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.2222 - val_loss: 114.2825\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.3982 - val_loss: 113.8531\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.5985 - val_loss: 110.0179\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.9752 - val_loss: 115.8618\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.7837 - val_loss: 109.7338\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 2.1517 - val_loss: 112.2822\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 2.1904 - val_loss: 120.0069\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 3.8684 - val_loss: 145.1279\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 15.4160 - val_loss: 119.3255\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 8.0753 - val_loss: 108.5084\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 4.1653 - val_loss: 129.6474\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 2.8987 - val_loss: 108.2152\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 3.0307 - val_loss: 109.9640\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 2.1680 - val_loss: 112.1168\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 1.1995 - val_loss: 113.0184\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.7150 - val_loss: 109.5828\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.5833 - val_loss: 110.7832\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.2747 - val_loss: 110.9571\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.1429 - val_loss: 110.1761\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.1172 - val_loss: 109.8056\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.1277 - val_loss: 111.1925\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.0733 - val_loss: 111.4630\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.0377 - val_loss: 111.0151\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.0296 - val_loss: 111.6829\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 0.0273 - val_loss: 111.0446\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.0304 - val_loss: 110.9904\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 0s 172us/step - loss: 0.0225 - val_loss: 111.5460\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.0168 - val_loss: 111.9846\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0266 - val_loss: 111.8907\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.0182 - val_loss: 111.0495\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0315 - val_loss: 111.1245\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0846 - val_loss: 113.1810\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1683 - val_loss: 110.1527\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.3544 - val_loss: 113.8051\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.5765 - val_loss: 111.2319\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 1.5651 - val_loss: 114.2194\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 5.1829 - val_loss: 109.6982\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 6.4818 - val_loss: 117.3923\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 7.7832 - val_loss: 110.7394\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 3.6217 - val_loss: 113.5546\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 1.9356 - val_loss: 113.7298\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.3319 - val_loss: 116.1297\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.7094 - val_loss: 111.0410\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.5875 - val_loss: 110.8661\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3558 - val_loss: 111.8848\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.6341 - val_loss: 113.9245\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.4792 - val_loss: 112.5964\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.2342 - val_loss: 113.3689\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.1274 - val_loss: 111.3310\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1281 - val_loss: 110.8070\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1046 - val_loss: 112.8876\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.1651 - val_loss: 111.3858\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0875 - val_loss: 112.0631\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0614 - val_loss: 113.4034\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1044 - val_loss: 110.0883\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1335 - val_loss: 113.2629\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.1841 - val_loss: 110.9213\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.5214 - val_loss: 110.5230\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.7868 - val_loss: 113.5105\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.9073 - val_loss: 113.0730\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.5801 - val_loss: 119.1966\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 1.2918 - val_loss: 112.8709\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 1.5597 - val_loss: 118.8140\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 2.1939 - val_loss: 108.7168\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 1.2444 - val_loss: 112.0001\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6951 - val_loss: 115.9415\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 2.8309 - val_loss: 111.8826\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 4.0944 - val_loss: 112.8600\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 2.2874 - val_loss: 115.1055\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 3.1611 - val_loss: 116.9926\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 3.2405 - val_loss: 119.3837\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 2.6424 - val_loss: 112.1014\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 1.1403 - val_loss: 111.6139\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.5164 - val_loss: 115.7692\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.3870 - val_loss: 114.8386\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.3345 - val_loss: 110.7906\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.3842 - val_loss: 111.7620\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2331 - val_loss: 112.9994\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.2796 - val_loss: 113.1866\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.4352 - val_loss: 112.1024\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.5027 - val_loss: 112.6093\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4483 - val_loss: 110.7432\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.3385 - val_loss: 114.4800\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 0.5249 - val_loss: 111.2769\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 1.2472 - val_loss: 117.1287\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 2.8645 - val_loss: 122.3643\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 2.1534 - val_loss: 106.8748\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 2.1437 - val_loss: 110.2160\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.7199 - val_loss: 109.4333\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.5904 - val_loss: 112.1803\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.5464 - val_loss: 109.7822\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.3524 - val_loss: 109.5828\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.6238 - val_loss: 110.1092\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.7938 - val_loss: 111.2024\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.9484 - val_loss: 115.6700\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 1.1010 - val_loss: 111.0604\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 1.1751 - val_loss: 110.6049\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.8269 - val_loss: 111.2144\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 2.0410 - val_loss: 124.8965\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 8.7914 - val_loss: 132.6742\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 4.3807 - val_loss: 122.4004\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 2.1354 - val_loss: 116.6988\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 1.9603 - val_loss: 124.8571\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 2.1348 - val_loss: 111.0062\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.9668 - val_loss: 112.4625\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.1009 - val_loss: 117.1944\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.4050 - val_loss: 114.6244\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3403 - val_loss: 111.6378\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2340 - val_loss: 114.5773\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.3717 - val_loss: 112.3142\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.5888 - val_loss: 115.0278\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.2793 - val_loss: 112.9421\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1373 - val_loss: 113.3272\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2047 - val_loss: 112.3102\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1495 - val_loss: 111.9441\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.1862 - val_loss: 112.0852\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1123 - val_loss: 112.5487\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.0880 - val_loss: 114.0228\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0646 - val_loss: 112.7476\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0539 - val_loss: 111.3312\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.1030 - val_loss: 112.8897\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0981 - val_loss: 112.9611\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1157 - val_loss: 112.9873\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.1960 - val_loss: 109.2272\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 2.5351 - val_loss: 115.7845\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 2.8535 - val_loss: 117.4736\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 4.3304 - val_loss: 113.2210\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 4.7236 - val_loss: 111.3419\n",
      "Epoch 515/1000\n",
      "1408/1500 [===========================>..] - ETA: 0s - loss: 1.7668"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_1d, y_train, batch_size=32, epochs=1000, validation_data=(x_val_1d, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 학습과정 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-eee722ea24a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plot.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = model.predict(x_test, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_raw = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras_study]",
   "language": "python",
   "name": "conda-env-keras_study-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
