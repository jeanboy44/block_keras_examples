{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비하기\n",
    " - https://tykimos.github.com/Keras/warehouse/2017-3-8_CNN_Getting_Started_handwriting_shape.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(3)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range=10,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 shear_range=0.7,\n",
    "                                 zoom_range=[0.9, 2.2],\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data/hard_handwriting_shape/train',\n",
    "    target_size = (24, 24),\n",
    "    batch_size = 3,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'data/hard_handwriting_shape/test',\n",
    "    target_size = (24, 24),\n",
    "    batch_size = 3,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구성하기\n",
    "ImportError: Could not import PIL.Image. The use of `array_to_img` requires PIL  \n",
    "이와 같은 에러 발생 시, 아래와 같이 조치함  \n",
    "conda remove pillow  \n",
    "pip install pillow  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 22, 22, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 20, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 839,107\n",
      "Trainable params: 839,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                activation='relu',\n",
    "                input_shape=(24,24,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습과정 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.6619 - acc: 0.6991 - val_loss: 0.1489 - val_acc: 0.9333\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3185 - acc: 0.8840 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2172 - acc: 0.9216 - val_loss: 0.6051 - val_acc: 0.8667\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1719 - acc: 0.9398 - val_loss: 0.1057 - val_acc: 0.9333\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1354 - acc: 0.9533 - val_loss: 1.0652 - val_acc: 0.8000\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1156 - acc: 0.9591 - val_loss: 0.0334 - val_acc: 1.0000\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0888 - acc: 0.9669 - val_loss: 0.0353 - val_acc: 1.0000\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0916 - acc: 0.9691 - val_loss: 0.1809 - val_acc: 0.9333\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0818 - acc: 0.9720 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 10/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0781 - acc: 0.9751 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 11/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0681 - acc: 0.9784 - val_loss: 5.4336e-04 - val_acc: 1.0000\n",
      "Epoch 12/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0581 - acc: 0.9816 - val_loss: 5.9064e-04 - val_acc: 1.0000\n",
      "Epoch 13/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0602 - acc: 0.9813 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 14/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0497 - acc: 0.9818 - val_loss: 1.2223e-04 - val_acc: 1.0000\n",
      "Epoch 15/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0496 - acc: 0.9847 - val_loss: 1.2150e-04 - val_acc: 1.0000\n",
      "Epoch 16/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0598 - acc: 0.9811 - val_loss: 5.2175e-06 - val_acc: 1.0000\n",
      "Epoch 17/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0438 - acc: 0.9878 - val_loss: 6.5370e-05 - val_acc: 1.0000\n",
      "Epoch 18/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0525 - acc: 0.9840 - val_loss: 1.3366e-04 - val_acc: 1.0000\n",
      "Epoch 19/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0469 - acc: 0.9853 - val_loss: 5.5361e-04 - val_acc: 1.0000\n",
      "Epoch 20/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0343 - acc: 0.9893 - val_loss: 2.4239e-07 - val_acc: 1.0000\n",
      "Epoch 21/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0471 - acc: 0.9860 - val_loss: 1.3749e-06 - val_acc: 1.0000\n",
      "Epoch 22/200\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0379 - acc: 0.9878 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 23/200\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0420 - acc: 0.9864 - val_loss: 3.0181e-05 - val_acc: 1.0000\n",
      "Epoch 24/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0455 - acc: 0.9864 - val_loss: 6.1194e-07 - val_acc: 1.0000\n",
      "Epoch 25/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0456 - acc: 0.9853 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 26/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0393 - acc: 0.9880 - val_loss: 6.4304e-05 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0377 - acc: 0.9884 - val_loss: 0.2759 - val_acc: 0.8667\n",
      "Epoch 28/200\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0369 - acc: 0.9889 - val_loss: 4.2094e-05 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0384 - acc: 0.9896 - val_loss: 6.3651e-04 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0363 - acc: 0.9876 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0312 - acc: 0.9907 - val_loss: 2.7021e-07 - val_acc: 1.0000\n",
      "Epoch 32/200\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0419 - acc: 0.9882 - val_loss: 0.2121 - val_acc: 0.9333\n",
      "Epoch 33/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0350 - acc: 0.9916 - val_loss: 3.1606e-04 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0250 - acc: 0.9922 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0357 - acc: 0.9891 - val_loss: 8.5208e-04 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0333 - acc: 0.9902 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0397 - acc: 0.9900 - val_loss: 7.5980e-06 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0301 - acc: 0.9907 - val_loss: 1.0147e-04 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0287 - acc: 0.9920 - val_loss: 2.1458e-07 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0344 - acc: 0.9900 - val_loss: 8.1460e-07 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0319 - acc: 0.9918 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0246 - acc: 0.9940 - val_loss: 2.3663e-05 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0384 - acc: 0.9893 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0257 - acc: 0.9922 - val_loss: 0.7371 - val_acc: 0.9333\n",
      "Epoch 45/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0220 - acc: 0.9938 - val_loss: 0.3491 - val_acc: 0.9333\n",
      "Epoch 46/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0328 - acc: 0.9911 - val_loss: 0.4201 - val_acc: 0.9333\n",
      "Epoch 47/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0391 - acc: 0.9909 - val_loss: 6.6385e-05 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0430 - acc: 0.9891 - val_loss: 2.0781e-05 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0372 - acc: 0.9896 - val_loss: 0.0565 - val_acc: 0.9333\n",
      "Epoch 50/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0234 - acc: 0.9929 - val_loss: 6.7952e-06 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0260 - acc: 0.9931 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0235 - acc: 0.9929 - val_loss: 0.0489 - val_acc: 0.9333\n",
      "Epoch 53/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0339 - acc: 0.9927 - val_loss: 1.3510e-07 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0386 - acc: 0.9902 - val_loss: 2.7021e-07 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0237 - acc: 0.9933 - val_loss: 2.1000e-05 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0291 - acc: 0.9931 - val_loss: 3.4055e-06 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0258 - acc: 0.9942 - val_loss: 3.6558e-07 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0272 - acc: 0.9933 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0145 - acc: 0.9956 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0252 - acc: 0.9929 - val_loss: 2.7021e-07 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0252 - acc: 0.9918 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0287 - acc: 0.9918 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0359 - acc: 0.9898 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0224 - acc: 0.9936 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0323 - acc: 0.9927 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0172 - acc: 0.9936 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0273 - acc: 0.9929 - val_loss: 4.3911e-05 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      " 482/1500 [========>.....................] - ETA: 5s - loss: 0.0320 - acc: 0.9917"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=15*100,\n",
    "    epochs=200,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "acc: 66.67%\n"
     ]
    }
   ],
   "source": [
    "print (\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_generator, steps=5)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Predict --\n",
      "{'circle': 0, 'rectangle': 1, 'triangle': 2}\n",
      "[[1.000 0.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.736 0.222 0.042]\n",
      " [1.000 0.000 0.000]\n",
      " [0.004 0.000 0.996]\n",
      " [0.000 1.000 0.000]\n",
      " [0.736 0.222 0.042]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.089 0.013 0.898]\n",
      " [0.004 0.593 0.403]]\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras_study]",
   "language": "python",
   "name": "conda-env-keras_study-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
